NAME: Cody Hubbard
EMAIL: CodySpHubbard@Gmail.com
ID: 004843389

FILES INCLUDED (13):
(1) - README 
(2) - lab2_list.c
	A C source module for project 2a. a C program that implements and tests a linked list function, 
	implements several specified command line options; threads, iterations, yield, sync, and produces the 
	specified output statistics as csv.
(3) - SortedList.h
	A header file (supplied by faculty) describing the interfaces for linked list operations.
(4) - SortedList.c
	A C source module for project 2a.  implements insert, delete, lookup, and length methods for a 
	sorted doubly linked list (described in the SortedList.h header file, including correct placement
	of yield calls).
(5) - Makefile
	A simple makefile that builds, cleans, and tars.
(6) - lab2b_list.csv
	CSV file containing all of my results for all of the tests in sample.sh.
(7) - profile.out -  execution profiling report showing where time was spent in the un-partitioned 
	spin-lock implementation.
(8) - 5 graphs 
	(.png files), created by running gnuplot(1) on the above .csv file with a modified version of the 
	supplied data reduction scripts.
NOTES:
	
-----------------------------------------------------------------------------------------------------------------

SOUTIONS TO QUESTIONS:
	
QUESTION 2.3.1 - Cycles in the basic list implementation:
Where do you believe most of the cycles are spent in the 1 and 2-thread list tests?
Why do you believe these to be the most expensive parts of the code?
Where do you believe most of the time/cycles are being spent in the high-thread spin-lock tests?
Where do you believe most of the time/cycles are being spent in the high-thread mutex tests?
ANSWER:
	For a one-threaded list the time spent doing lock test as well as list operations is probably equal.
	For a two-threaded list the answer is not really certain.
	In the high-threaded spin lock test most of the operations go to spinning, lock contention.
	In the high-threaded mutex lock test most of the operations go to list operations.
	
QUESTION 2.3.2 - Execution Profiling:
Where (what lines of code) are consuming most of the cycles when the spin-lock version of the list exercise 
is run with a large number of threads?
Why does this operation become so expensive with large numbers of threads?
ANSWER:
	The operation becasomes so expensive with a large number of threads becasue the lock contention increases and the 
	list itself becomes extremely long.
	
QUESTION 2.3.3 - Mutex Wait Time:
Look at the average time per operation (vs. # threads) and the average wait-for-mutex time (vs. #threads).
Why does the average lock-wait time rise so dramatically with the number of contending threads?
Why does the completion time per operation rise (less dramatically) with the number of contending threads?
How is it possible for the wait time per operation to go up faster (or higher) than the completion time per operation?
ANSWER:
	The wait time raises so dramatically becasue when the number of threads increases the list length also grows dramatically.
	The completion time per opertaion rises less dramaticaly becasue it is just wall time, while the lock
	wait time is addative for all threads which may be running concurrently.
	The wait time per operation can go up faster and/or higher than the completion time becasue of the concurrency of the threads.
	Multiple threads running at once may rack up a bunch of wait time while still reducing the overall completion time.
	
QUESTION 2.3.4 - Performance of Partitioned Lists
Explain the change in performance of the synchronized methods as a function of the number of lists.
Should the throughput continue increasing as the number of lists is further increased? If not, explain why not.
It seems reasonable to suggest the throughput of an N-way partitioned list should be equivalent to the throughput 
of a single list with fewer (1/N) threads. Does this appear to be true in the above curves? If not, explain why not.
ANSWER:
	The throughput increases as the number of lists increases. This is unsuprising becasue the goal of the lists is to 
	increase efficency, therefore increasing throughput.
	The throughput will eventually max out, or even decrease as the number of lists is further increased. This is becasue
	when the number of lists exceeds the number of cores parallelism will decrease and efficency/throughput will decrease as well.
	This does not appear to true in the curves. And this is due to the fact that having more lists does not equivalently increase 
	throughput. The use of multithreading is what really allows for parallelism and increases the throughput. using multiple lists
	just helps multithreading work better.
	